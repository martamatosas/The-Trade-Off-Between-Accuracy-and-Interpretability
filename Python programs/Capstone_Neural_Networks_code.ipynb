{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unpickle data\n",
    "data = pd.read_pickle('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      M\n",
       "1      M\n",
       "2      M\n",
       "3      M\n",
       "4      M\n",
       "      ..\n",
       "564    M\n",
       "565    M\n",
       "566    M\n",
       "567    M\n",
       "568    B\n",
       "Name: diagnosis, Length: 569, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate target and features\n",
    "target = 'diagnosis'\n",
    "y = data[target]\n",
    "X = data.drop(columns=[target])\n",
    "features_list = ['texture_mean', 'area_worst', 'smoothness_worst', 'area_mean', 'concavity_mean']\n",
    "X = X[features_list]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>22.15</td>\n",
       "      <td>2398.0</td>\n",
       "      <td>0.15120</td>\n",
       "      <td>1260.0</td>\n",
       "      <td>0.147900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>25.56</td>\n",
       "      <td>1021.0</td>\n",
       "      <td>0.12430</td>\n",
       "      <td>948.0</td>\n",
       "      <td>0.168200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>532</th>\n",
       "      <td>16.33</td>\n",
       "      <td>773.4</td>\n",
       "      <td>0.12640</td>\n",
       "      <td>575.5</td>\n",
       "      <td>0.017520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>21.41</td>\n",
       "      <td>579.5</td>\n",
       "      <td>0.09388</td>\n",
       "      <td>507.4</td>\n",
       "      <td>0.031120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>21.25</td>\n",
       "      <td>715.5</td>\n",
       "      <td>0.12870</td>\n",
       "      <td>603.4</td>\n",
       "      <td>0.014620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>18.75</td>\n",
       "      <td>719.8</td>\n",
       "      <td>0.16240</td>\n",
       "      <td>551.1</td>\n",
       "      <td>0.042010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>18.70</td>\n",
       "      <td>1321.0</td>\n",
       "      <td>0.12800</td>\n",
       "      <td>1033.0</td>\n",
       "      <td>0.177200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>17.07</td>\n",
       "      <td>542.5</td>\n",
       "      <td>0.09958</td>\n",
       "      <td>421.0</td>\n",
       "      <td>0.008306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>18.00</td>\n",
       "      <td>622.1</td>\n",
       "      <td>0.12890</td>\n",
       "      <td>506.3</td>\n",
       "      <td>0.038890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>13.90</td>\n",
       "      <td>326.6</td>\n",
       "      <td>0.18500</td>\n",
       "      <td>257.8</td>\n",
       "      <td>0.033320</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>398 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     texture_mean  area_worst  smoothness_worst  area_mean  concavity_mean\n",
       "18          22.15      2398.0           0.15120     1260.0        0.147900\n",
       "213         25.56      1021.0           0.12430      948.0        0.168200\n",
       "532         16.33       773.4           0.12640      575.5        0.017520\n",
       "191         21.41       579.5           0.09388      507.4        0.031120\n",
       "235         21.25       715.5           0.12870      603.4        0.014620\n",
       "..            ...         ...               ...        ...             ...\n",
       "526         18.75       719.8           0.16240      551.1        0.042010\n",
       "53          18.70      1321.0           0.12800     1033.0        0.177200\n",
       "350         17.07       542.5           0.09958      421.0        0.008306\n",
       "79          18.00       622.1           0.12890      506.3        0.038890\n",
       "520         13.90       326.6           0.18500      257.8        0.033320\n",
       "\n",
       "[398 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the dataset into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, \n",
    "                                                    random_state=100) \n",
    "                                                    #stratify=y)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.000e+00, 2.215e+01, 2.398e+03, 1.512e-01, 1.260e+03, 1.479e-01],\n",
       "       [1.000e+00, 2.556e+01, 1.021e+03, 1.243e-01, 9.480e+02, 1.682e-01],\n",
       "       [1.000e+00, 1.633e+01, 7.734e+02, 1.264e-01, 5.755e+02, 1.752e-02],\n",
       "       ...,\n",
       "       [1.000e+00, 1.707e+01, 5.425e+02, 9.958e-02, 4.210e+02, 8.306e-03],\n",
       "       [1.000e+00, 1.800e+01, 6.221e+02, 1.289e-01, 5.063e+02, 3.889e-02],\n",
       "       [1.000e+00, 1.390e+01, 3.266e+02, 1.850e-01, 2.578e+02, 3.332e-02]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup inputs and expected outputs \n",
    "cols = features_list\n",
    "\n",
    "# inputs to Logistic Regression (via Tensorflow)\n",
    "X_trainTf = X_train[cols].values\n",
    "X_testTf = X_test[cols].values\n",
    "\n",
    "# add constant columns to both\n",
    "X_trainTf = np.hstack((np.ones((X_trainTf.shape[0], 1)), X_trainTf))\n",
    "X_testTf = np.hstack((np.ones((X_testTf.shape[0], 1)), X_testTf))\n",
    "X_trainTf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "le = LabelEncoder()\n",
    "y_test = le.fit_transform(y_test)\n",
    "y_train = le.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# expectd outputs:\n",
    "y_trainTf = y_train.reshape(-1,1)\n",
    "y_testTf = y_test.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "13/13 [==============================] - 0s 755us/step - loss: 2143.8462 - accuracy: 0.5452\n",
      "Epoch 2/10\n",
      "13/13 [==============================] - 0s 918us/step - loss: 2525.4854 - accuracy: 0.4950\n",
      "Epoch 3/10\n",
      "13/13 [==============================] - 0s 818us/step - loss: 2729.4387 - accuracy: 0.4849\n",
      "Epoch 4/10\n",
      "13/13 [==============================] - 0s 921us/step - loss: 2140.3938 - accuracy: 0.5327\n",
      "Epoch 5/10\n",
      "13/13 [==============================] - 0s 872us/step - loss: 2013.6212 - accuracy: 0.5603\n",
      "Epoch 6/10\n",
      "13/13 [==============================] - 0s 1ms/step - loss: 1708.1113 - accuracy: 0.5553\n",
      "Epoch 7/10\n",
      "13/13 [==============================] - 0s 996us/step - loss: 1632.3896 - accuracy: 0.5854\n",
      "Epoch 8/10\n",
      "13/13 [==============================] - 0s 995us/step - loss: 1087.8041 - accuracy: 0.6030\n",
      "Epoch 9/10\n",
      "13/13 [==============================] - 0s 931us/step - loss: 2302.4617 - accuracy: 0.5201\n",
      "Epoch 10/10\n",
      "13/13 [==============================] - 0s 765us/step - loss: 1413.7551 - accuracy: 0.5754\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9f7f18d150>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "\n",
    "model = tf.keras.models.Sequential([ tf.keras.layers.Flatten(), tf.keras.layers.Dense(2, activation=tf.nn.softmax) ])\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# train\n",
    "model.fit(X_trainTf, y_trainTf, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluate on test data\n",
      "2/2 [==============================] - 0s 744us/step - loss: 342.1758 - accuracy: 0.8304\n",
      "Test loss:  342.17584228515625\n",
      "Test acc:  0.8304093480110168\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model \n",
    "print(\"Evaluate on test data\")\n",
    "results = model.evaluate(X_testTf, y_testTf, batch_size=128)\n",
    "print(\"Test loss: \", results[0])\n",
    "print(\"Test acc: \", results[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert outputs into array of binary -> [0,1],[1,0],...\n",
    "from keras.utils import to_categorical\n",
    "y_train_binary = to_categorical(y_trainTf)\n",
    "y_test_binary = to_categorical(y_testTf)\n",
    "\n",
    "y_train_binary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(398, 1)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define hyperparameters\n",
    "num_classes = len(np.unique(y_trainTf))\n",
    "num_features = X_trainTf.shape[1]\n",
    "\n",
    "input_layer = num_features # rename\n",
    "\n",
    "learning_rate = 0.01\n",
    "training_steps = 1000\n",
    "batch_size = 256\n",
    "display_step = 50\n",
    "\n",
    "y_trainTf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 6)]               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 15)                105       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                160       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2)                 22        \n",
      "=================================================================\n",
      "Total params: 287\n",
      "Trainable params: 287\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# model training \n",
    "from tensorflow.keras.layers import Input, Dense, Activation,Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "input_layer = Input(shape=(num_features,)) # number of features\n",
    "dense_layer_1 = Dense(15, activation='relu')(input_layer)\n",
    "dense_layer_2 = Dense(10, activation='relu')(dense_layer_1)\n",
    "output = Dense(y_train_binary.shape[1], activation='softmax')(dense_layer_2)\n",
    "\n",
    "# define model\n",
    "model = Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "# definre optimizer (Adam) and learning rate\n",
    "opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "# compile the model, with loss categorical cross entropy and accuracy metric\n",
    "model.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['acc'])\n",
    "\n",
    "# Compile the model\n",
    "#model.compile(optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "#              loss='sparse_categorical_crossentropy',\n",
    "#              metrics=['accuracy'], learning_rate=0.01)\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "7/7 [==============================] - 0s 16ms/step - loss: 22.6744 - acc: 0.4528 - val_loss: 6.5398 - val_acc: 0.4375\n",
      "Epoch 2/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 5.2771 - acc: 0.3931 - val_loss: 2.2716 - val_acc: 0.4125\n",
      "Epoch 3/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 1.7287 - acc: 0.4528 - val_loss: 0.7262 - val_acc: 0.5625\n",
      "Epoch 4/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.9523 - acc: 0.5912 - val_loss: 0.4206 - val_acc: 0.8375\n",
      "Epoch 5/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3819 - acc: 0.8522 - val_loss: 0.3347 - val_acc: 0.8500\n",
      "Epoch 6/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3368 - acc: 0.8679 - val_loss: 0.3577 - val_acc: 0.8625\n",
      "Epoch 7/50\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.3179 - acc: 0.8648 - val_loss: 0.3359 - val_acc: 0.8625\n",
      "Epoch 8/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2992 - acc: 0.9025 - val_loss: 0.3309 - val_acc: 0.8625\n",
      "Epoch 9/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2999 - acc: 0.8868 - val_loss: 0.3179 - val_acc: 0.8500\n",
      "Epoch 10/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3243 - acc: 0.8648 - val_loss: 0.3476 - val_acc: 0.8750\n",
      "Epoch 11/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4095 - acc: 0.8270 - val_loss: 0.4497 - val_acc: 0.7750\n",
      "Epoch 12/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5149 - acc: 0.8145 - val_loss: 0.3799 - val_acc: 0.8625\n",
      "Epoch 13/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5050 - acc: 0.8019 - val_loss: 0.3695 - val_acc: 0.8500\n",
      "Epoch 14/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4253 - acc: 0.8585 - val_loss: 0.4558 - val_acc: 0.8375\n",
      "Epoch 15/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3814 - acc: 0.8805 - val_loss: 0.3893 - val_acc: 0.8500\n",
      "Epoch 16/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2928 - acc: 0.9057 - val_loss: 0.3165 - val_acc: 0.8625\n",
      "Epoch 17/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2704 - acc: 0.9057 - val_loss: 0.3989 - val_acc: 0.8625\n",
      "Epoch 18/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3824 - acc: 0.8648 - val_loss: 0.3029 - val_acc: 0.8625\n",
      "Epoch 19/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3754 - acc: 0.8491 - val_loss: 0.4592 - val_acc: 0.7875\n",
      "Epoch 20/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.5262 - acc: 0.7925 - val_loss: 0.5835 - val_acc: 0.7625\n",
      "Epoch 21/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4597 - acc: 0.8302 - val_loss: 0.2941 - val_acc: 0.8750\n",
      "Epoch 22/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3160 - acc: 0.8868 - val_loss: 0.3307 - val_acc: 0.8625\n",
      "Epoch 23/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2982 - acc: 0.8805 - val_loss: 0.7325 - val_acc: 0.7875\n",
      "Epoch 24/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3852 - acc: 0.8679 - val_loss: 0.3193 - val_acc: 0.8625\n",
      "Epoch 25/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4421 - acc: 0.8491 - val_loss: 0.3644 - val_acc: 0.8625\n",
      "Epoch 26/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4489 - acc: 0.8459 - val_loss: 0.5595 - val_acc: 0.7750\n",
      "Epoch 27/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4926 - acc: 0.8113 - val_loss: 0.4565 - val_acc: 0.7875\n",
      "Epoch 28/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.4076 - acc: 0.8365 - val_loss: 0.3083 - val_acc: 0.8500\n",
      "Epoch 29/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3377 - acc: 0.8711 - val_loss: 0.3412 - val_acc: 0.8750\n",
      "Epoch 30/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3281 - acc: 0.8774 - val_loss: 0.3024 - val_acc: 0.8750\n",
      "Epoch 31/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3927 - acc: 0.8491 - val_loss: 0.3217 - val_acc: 0.8625\n",
      "Epoch 32/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2721 - acc: 0.8931 - val_loss: 0.3062 - val_acc: 0.8625\n",
      "Epoch 33/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2631 - acc: 0.9025 - val_loss: 0.2915 - val_acc: 0.8625\n",
      "Epoch 34/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3019 - acc: 0.8836 - val_loss: 0.3030 - val_acc: 0.8500\n",
      "Epoch 35/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2823 - acc: 0.8962 - val_loss: 0.4303 - val_acc: 0.8625\n",
      "Epoch 36/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2884 - acc: 0.9057 - val_loss: 0.3081 - val_acc: 0.8625\n",
      "Epoch 37/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2684 - acc: 0.8962 - val_loss: 0.3236 - val_acc: 0.8625\n",
      "Epoch 38/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2684 - acc: 0.8962 - val_loss: 0.2907 - val_acc: 0.8625\n",
      "Epoch 39/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2587 - acc: 0.9057 - val_loss: 0.3002 - val_acc: 0.8750\n",
      "Epoch 40/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2852 - acc: 0.9057 - val_loss: 0.2873 - val_acc: 0.8625\n",
      "Epoch 41/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2564 - acc: 0.9057 - val_loss: 0.2823 - val_acc: 0.8625\n",
      "Epoch 42/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2498 - acc: 0.9151 - val_loss: 0.2825 - val_acc: 0.8625\n",
      "Epoch 43/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2691 - acc: 0.9088 - val_loss: 0.2719 - val_acc: 0.8750\n",
      "Epoch 44/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2853 - acc: 0.8931 - val_loss: 0.3931 - val_acc: 0.8625\n",
      "Epoch 45/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2945 - acc: 0.8805 - val_loss: 0.2765 - val_acc: 0.8750\n",
      "Epoch 46/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2993 - acc: 0.8836 - val_loss: 0.2710 - val_acc: 0.8750\n",
      "Epoch 47/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.2615 - acc: 0.8994 - val_loss: 0.3651 - val_acc: 0.8875\n",
      "Epoch 48/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3334 - acc: 0.8899 - val_loss: 0.4852 - val_acc: 0.7875\n",
      "Epoch 49/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3550 - acc: 0.8459 - val_loss: 0.3750 - val_acc: 0.8625\n",
      "Epoch 50/50\n",
      "7/7 [==============================] - 0s 3ms/step - loss: 0.3869 - acc: 0.8396 - val_loss: 0.3764 - val_acc: 0.8750\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_trainTf, y_train_binary, batch_size=50, epochs=50, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 899us/step - loss: 0.3671 - acc: 0.8363\n",
      "Test Score: 0.36706289649009705\n",
      "Test Accuracy: 0.8362573385238647\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_testTf, y_test_binary, verbose=1)\n",
    "\n",
    "print(\"Test Score:\", score[0])\n",
    "print(\"Test Accuracy:\", score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
